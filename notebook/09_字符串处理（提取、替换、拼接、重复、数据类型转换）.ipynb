{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7379e5db",
   "metadata": {},
   "source": [
    "# PySpark 字符串处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe77f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db24c2",
   "metadata": {},
   "source": [
    "## 基本字符串处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bae89",
   "metadata": {},
   "source": [
    "### 字符串格式拼接字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797884ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+\n",
      "|  a|    b|      v|\n",
      "+---+-----+-------+\n",
      "|  5|hello|5 hello|\n",
      "+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(5, \"hello\")], ['a', 'b'])\n",
    "df = df.withColumn('v', F.format_string('%d %s', df.a, df.b))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1b461",
   "metadata": {},
   "source": [
    "### 字符串位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97548332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|pos|\n",
      "+---+\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.instr(df.v, 'h').alias('pos')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a89f87",
   "metadata": {},
   "source": [
    "### 字符串截取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479aa601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|substring|\n",
      "+---------+\n",
      "|    5 hel|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.substring(df.v, 1, 5).alias('substring')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9806b",
   "metadata": {},
   "source": [
    "## 替换 `DataFrame` 中的列值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a679a2a",
   "metadata": {},
   "source": [
    "- `regexp_replace()`、`translate()`、 `overlay()`来替换 `PySpark DataFrame` 的列值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837cf1c",
   "metadata": {},
   "source": [
    "### 创建一个带有一些地址的 `PySpark DataFrame`\n",
    "使用这个 DataFrame 来解释如何替换列值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c269c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n",
      "| id|           address|state|\n",
      "+---+------------------+-----+\n",
      "|  1|  14851 Jeffrey Rd|   DE|\n",
      "|  2|43421 Margarita St|   NY|\n",
      "|  3|  13111 Siemon Ave|   CA|\n",
      "+---+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "address = [\n",
    "    (1,\"14851 Jeffrey Rd\",\"DE\"),\n",
    "    (2,\"43421 Margarita St\",\"NY\"),\n",
    "    (3,\"13111 Siemon Ave\",\"CA\")]\n",
    "df =spark.createDataFrame(\n",
    "    address, [\"id\", \"address\", \"state\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b95bfe",
   "metadata": {},
   "source": [
    "### `regexp_replace()`替换字符串列值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1d85f",
   "metadata": {},
   "source": [
    "使用正则表达式进行匹配，如果正则表达式不匹配则返回空字符串，\n",
    "\n",
    "下面的示例将字段`address`名称`Rd`值替换为`Road`字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b824d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n",
      "| id|           address|state|\n",
      "+---+------------------+-----+\n",
      "|  1|14851 Jeffrey Road|   DE|\n",
      "|  2|43421 Margarita St|   NY|\n",
      "|  3|  13111 Siemon Ave|   CA|\n",
      "+---+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('address', F.regexp_replace('address', 'Rd', 'Road')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840c78c",
   "metadata": {},
   "source": [
    "### 有条件地替换列值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ac439d",
   "metadata": {},
   "source": [
    "在上面的例子中，只是替换`Rd`，但没有替换`St`和`Ave`，\n",
    "使用`when().otherwise()`条件函数有条件地替换列值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355b07c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------+-----+\n",
      "|id |address               |state|\n",
      "+---+----------------------+-----+\n",
      "|1  |14851 Jeffrey Road    |DE   |\n",
      "|2  |43421 Margarita Street|NY   |\n",
      "|3  |13111 Siemon Avenue   |CA   |\n",
      "+---+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('address', \n",
    "    F.when(df.address.endswith('Rd'), F.regexp_replace(df.address,'Rd','Road'))\\\n",
    "   .when(df.address.endswith('St'), F.regexp_replace(df.address,'St','Street'))\\\n",
    "   .when(df.address.endswith('Ave'), F.regexp_replace(df.address,'Ave','Avenue'))\\\n",
    "   .otherwise(df.address)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb515c2",
   "metadata": {},
   "source": [
    "### 用字典替换列值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74cf0c7",
   "metadata": {},
   "source": [
    "在下面的示例中，我们将`state`列的字符串值替换为字典键值对中的完整缩写名称，\n",
    "为此我使用`PySpark map()`来循环遍历 `DataFrame` 的每一行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752a0ca",
   "metadata": {},
   "source": [
    "#### 方法一："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d93d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------+\n",
      "| id|           address|     state|\n",
      "+---+------------------+----------+\n",
      "|  1|  14851 Jeffrey Rd|  Delaware|\n",
      "|  2|43421 Margarita St|  New York|\n",
      "|  3|  13111 Siemon Ave|California|\n",
      "+---+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stateDic={'CA':'California','NY':'New York','DE':'Delaware'}\n",
    "df2=df.rdd.map(lambda x: (x.id, x.address, stateDic[x.state]))\\\n",
    "    .toDF([\"id\", \"address\", \"state\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11437303",
   "metadata": {},
   "source": [
    "#### 方法二："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfded3",
   "metadata": {},
   "source": [
    "- 参数：`subset` 指定要替换的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d959d3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------+\n",
      "| id|           address|     state|\n",
      "+---+------------------+----------+\n",
      "|  1|  14851 Jeffrey Rd|  Delaware|\n",
      "|  2|43421 Margarita St|  New York|\n",
      "|  3|  13111 Siemon Ave|California|\n",
      "+---+------------------+----------+\n",
      "\n",
      "+---+------------------+----------+\n",
      "| id|           address|     state|\n",
      "+---+------------------+----------+\n",
      "|  1|  14851 Jeffrey Rd|  Delaware|\n",
      "|  2|43421 Margarita St|  New York|\n",
      "|  3|  13111 Siemon Ave|California|\n",
      "+---+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.replace(stateDic, subset='state').show()\n",
    "# 或者\n",
    "df.replace(list(stateDic.keys()), list(stateDic.values()), subset='state').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beafd54",
   "metadata": {},
   "source": [
    "### 逐个字符替换列值`translate()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2eb272",
   "metadata": {},
   "source": [
    "逐个字符地替换 `DataFrame` 列值。在下面的例子中，\n",
    "每一个字符`1`替换为`A`，`2`替换为`B`，`3`替换为`C`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7561fbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n",
      "| id|           address|state|\n",
      "+---+------------------+-----+\n",
      "|  1|  A485A Jeffrey Rd|   DE|\n",
      "|  2|4C4BA Margarita St|   NY|\n",
      "|  3|  ACAAA Siemon Ave|   CA|\n",
      "+---+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('address', F.translate('address', '123', 'ABC')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a2c0b",
   "metadata": {},
   "source": [
    "### 用另一个列值替换列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a6e34",
   "metadata": {},
   "source": [
    "通过使用`expr()` 和 `regexp_replace()`可以用另一个 `DataFrame column` 中的值替换列值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640296d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+----------+\n",
      "|     col1|col2|col3|new_column|\n",
      "+---------+----+----+----------+\n",
      "|ABCDE_XYZ| XYZ| FGH| ABCDE_FGH|\n",
      "+---------+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "   [(\"ABCDE_XYZ\", \"XYZ\",\"FGH\")], \n",
    "    (\"col1\", \"col2\",\"col3\"))\n",
    "df.withColumn(\n",
    "    \"new_column\", F.expr(\"regexp_replace(col1, col2, col3)\").alias(\"replaced_value\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a9cd90",
   "metadata": {},
   "source": [
    "### 使用`overlay()`函数，用来自另一列的字符串值替换列值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74958516",
   "metadata": {},
   "source": [
    "`overlay()`函数，用于从开始位置和字符数将字符串与另一个列字符串覆盖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1742866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+\n",
      "|     col1|col2|overlayed|\n",
      "+---------+----+---------+\n",
      "|ABCDE_XYZ| FGH|ABCDE_FGH|\n",
      "+---------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"ABCDE_XYZ\", \"FGH\")], (\"col1\", \"col2\"))\n",
    "df.select('col1', 'col2', F.overlay(\"col1\", \"col2\", 7).alias(\"overlayed\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce081055",
   "metadata": {},
   "source": [
    "## 正则表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a5e7",
   "metadata": {},
   "source": [
    "### 正则表达式提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa3e1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+-----+----+\n",
      "|    str|  pos-0|pos-1|pos-2|中文|\n",
      "+-------+-------+-----+-----+----+\n",
      "|100-200|100-200|  100|  200|中午|\n",
      "+-------+-------+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('100-200', '中午01')], ['str', 'cn'])\n",
    "df.select('str',\n",
    "    F.regexp_extract('str', '(\\d+)-(\\d+)', 0).alias('pos-0'),\n",
    "    F.regexp_extract('str', '(\\d+)-(\\d+)', 1).alias('pos-1'),\n",
    "    F.regexp_extract('str', '(\\d+)-(\\d+)', 2).alias('pos-2'),\n",
    "    F.regexp_extract(df.cn, \"[\\u4e00-\\u9fa5]+\", 0).alias('中文'),  # 提取全部的中文字符串\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d44034",
   "metadata": {},
   "source": [
    "### 字符串拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076cf5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "| concat|concat_ws|\n",
      "+-------+---------+\n",
      "|abcd123| abcd-123|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('abcd','123')], ['str', 'int'])\n",
    "df_new = df.select(\n",
    "    F.concat(df.str, df.int).alias('concat'),    # 直接拼接\n",
    "    F.concat_ws('-', df.str, df.int).alias('concat_ws'), # 指定拼接符\n",
    ")\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e99e5",
   "metadata": {},
   "source": [
    "### 字符串重复`repeat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a56407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|str 重复两次|\n",
      "+------------+\n",
      "|    abcdabcd|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df 中的 str 列重复两次\n",
    "df.select(F.repeat('str', 2).alias('str 重复两次')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95e0f9",
   "metadata": {},
   "source": [
    "### 分割`split`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411ab64",
   "metadata": {},
   "source": [
    "`F.split(str, pattern, limit=-1)`\n",
    "\n",
    "- `limit <= 0`: 展示全部的拆分内容\n",
    "- `limit > 0`: 不超过展示的最小条目数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "120cf322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+----------+-----------+\n",
      "|concat_ws|split array|          0|         1|          2|\n",
      "+---------+-----------+-----------+----------+-----------+\n",
      "| abcd-123|[abcd, 123]|[abcd, 123]|[abcd-123]|[abcd, 123]|\n",
      "+---------+-----------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.select(\n",
    "    'concat_ws',\n",
    "    F.split('concat_ws', '-', -1).alias('split array'), \n",
    "    F.split('concat_ws', '-', 0).alias('0'),\n",
    "    F.split('concat_ws', '-', 1).alias('1'),\n",
    "    F.split('concat_ws', '-', 2).alias('2'),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8de259",
   "metadata": {},
   "source": [
    "### `contains` 或 `rlike` 进行行选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c6b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "| concat|concat_ws|\n",
      "+-------+---------+\n",
      "|abcd123| abcd-123|\n",
      "+-------+---------+\n",
      "\n",
      "+-------+---------+\n",
      "| concat|concat_ws|\n",
      "+-------+---------+\n",
      "|abcd123| abcd-123|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 展示包含 - 的数据\n",
    "df_new.where(df_new.concat_ws.contains(\"-\")).show()\n",
    "\n",
    "# 展示包含 - 或 = 的数据\n",
    "df_new.where(df_new.concat_ws.rlike(\"-|=\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43728866",
   "metadata": {},
   "source": [
    "### 修改数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac49cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- str: string (nullable = true)\n",
      " |-- int: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('str', 'string'), ('int', 'bigint')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据类型\n",
    "df = spark.createDataFrame([('abcd', 123)], ['str', 'int'])\n",
    "df.printSchema()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5f665",
   "metadata": {},
   "source": [
    "#### 方式一：`withColumn` 覆盖原字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "516c14bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- str: string (nullable = true)\n",
      " |-- int: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cast\n",
    "df.withColumn('int', df.int.cast(DoubleType())).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd112ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- str: string (nullable = true)\n",
      " |-- int: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# astype\n",
    "df.withColumn(\"int\", df.int.astype(StringType())).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a7c1fa",
   "metadata": {},
   "source": [
    "#### 方式二：Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b918a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- int: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- int: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cast\n",
    "df.select(F.col('int').cast(StringType())).printSchema()\n",
    "\n",
    "# astype\n",
    "df.select(F.col('int').astype(StringType())).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2989a1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
